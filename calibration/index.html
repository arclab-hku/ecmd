<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>The ECMD Datasets | Calibration </title>
    <meta name="author" content="The ECMD Datasets " />
    <meta name="description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    <meta name="keywords" content="Event-based Vision, Multi-sensor, SLAM, Autonomous Driving" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="The ECMD Datasets  " />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The ECMD Datasets   | Calibration" />
    <meta property="og:url" content="http://localhost:4000/ecmd/sensors" />
    <meta property="og:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Calibration" />
    <meta name="twitter:description" content="An Event-Centric Multisensory Driving Dataset for SLAM.
" />
    
    

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "The ECMD Datasets  "
        },
        "url": "http://localhost:4000/ecmd/",
        "@type": "WebSite",
        "description": "An Event-Centric Multisensory Driving Dataset for SLAM.
",
        "headline": "Calibration",
        "sameAs": ["https://github.com/arclab-hku/Event_based_VO-VIO-SLAM", "https://arclab.hku.hk/"],
        "name": "The ECMD Datasets  ",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Barriecito&family=Poppins:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/PASTIE.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->

    <link rel="shortcut icon" href="https://arclab-hku.github.io/ecmd/assets/img/hku_logo.png"/>
    
    <link rel="stylesheet" href="https://arclab-hku.github.io/ecmd/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/ecmd/sensors">
    <link rel="stylesheet" href="https://arclab-hku.github.io/ecmd/assets/css/fonts.css">
    <link rel="stylesheet" href="/ecmd/assets/css/fonts.css">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/ecmd/"><span class="font-weight: 600">ECMD Dataset</span>   </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- Home -->
              <li class="nav-item">
                <a class="nav-link" href="/ecmd/">Home</a>
              </li>
              
              <!-- Other pages -->
                <li class="nav-item ">
                  <a class="nav-link" href="/ecmd/sensors/">Sensors</a>
                </li>
                <li class="nav-item active">
                  <a class="nav-link" href="/ecmd/calibration/">Calibration<span class="sr-only">(current)</span></a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/ecmd/download/">Download</a>
                </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>
<!-- 以上为include -->

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Calibration</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p><br></p>

  <!-- <figure style="text-align: center;"> -->
    <!-- <img style = "width: 90%" src="/ecmd/assets/img/sensors.png" alt="Image description"> -->
    <!-- 放一张类似于VECtor calibration的图片, 主要是表现各个传感器的相互关联图-->
 <!-- </figure> -->

<div style="text-align: center;">
  <picture>
    <img style="width: 90%;" class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/gif/calibration.gif" title="calibration">
  </picture>
</div>

<p><br></p>

<div style="text-align: center;">
  <table style="display: inline-block;">
  <!-- <table border="1" style="border-collapse: collapse;" > -->
    <tr>
      <td>Calibration rosbag</td>
      <td><a href="https://arclab-hku.github.io/ecmd/404">Event camera</a></td>
      <td><a href="https://arclab-hku.github.io/ecmd/404">Industrial camera</a></td>
      <td><a href="https://arclab-hku.github.io/ecmd/404">Infrared camera</a></td>
      <td><a href="https://arclab-hku.github.io/ecmd/404">LiDAR</a></td>
    </tr>
    <tr>
      <td>Calibration files</td>
      <td colspan="2"><a href="https://connecthkuhk-my.sharepoint.com/:u:/g/personal/chenpyhk_connect_hku_hk/EW1Wl8YIbUlGgFusgDteaB4BDgI-op1kEYay9unWViY4QA?e=XCeqQN">Checkboard files for Event/Industrial cameras</a></td>
      <td><a href="https://connecthkuhk-my.sharepoint.com/:u:/g/personal/chenpyhk_connect_hku_hk/Eb-P7J4gEshEtsCWYBY5-pIBmNTd1wfXaFNaAYNsfbRtYw?e=yS9gPs">Checkboard files for Infrared camera</a></td>
      <td><a href="https://connecthkuhk-my.sharepoint.com/:u:/g/personal/chenpyhk_connect_hku_hk/EeUN1jFa_05MpMwc2bRXLuIBkVj7ia0T5YqRwXziFWgRHQ?e=CcHgLE">The DXF file of infrared checkboard </a></td>
      <!-- <td><a href="https://arclab-hku.github.io/ecmd/404"></a></td> -->
    </tr>
  </table>
</div>

<p><br></p>

<!-- <h4><a href="https://github.com/mgaoling/mpl_calibration_toolbox" target="_blank" rel="noopener noreferrer">MPL Calibration Toolbox</a></h4>

<p><br></p>

<p>We provide an additional, easy-to-use toolbox to execute and reproduce the calibration tasks with detailed instructions. Related configuration files, data sequences, and calibration results can be found below.</p>

<p><br></p> -->

<h3>1. Time synchronization</h3>

<p><br></p>

<p style="text-align: justify;">
  We use a Precision Time Protocol (PTP) device to synchronize the clocks of various data collection devices across the sensor network. 
  The PTP ensures time accuracy within nanoseconds. 
  The synchronization device acquires the NMEA output and pulse-per-second (PPS) signal from a u-blox M8T GNSS receiver to align the ROS time of the onboard computers 
  with the GPS time. This enables sensors such as cameras, LiDAR, and IMU to record timestamps based on the synchronized GPS time.   
</p>

<figure style="text-align: center;">
  <img style = "width: 100%" src="https://arclab-hku.github.io/ecmd/assets/img/structure_of_syns.png" alt="Image description">
  <figcaption id="overview">Fig. 1. The Structure of Our Sensors Synchronization</figcaption>
</figure>


<p style="text-align: justify;">
  Moreover, to achieve time synchronization between different event cameras, the DAVIS346 on the rightmost side is configured as the master device and 
  transmits trigger signal pulses to the remaining slave event cameras sequentially from left to right via external cables.
</p>

<p style="text-align: justify;">
  The event camera has an additional synchronization interface, called as "sync connectors", as shown in the figure below. (Using DAVIS346 as example 
  reference to <a href="https://inivation.com/wp-content/uploads/2019/08/DAVIS346.pdf">Link</a>,
  same as DVXplorer <a href="https://inivation.com/wp-content/uploads/2023/03/DVXplorer.pdf">Link</a>).
</p>



<!-- <div style="display: flex; justify-content: space-between;">
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/syns_connectors.png" alt="Image 1" style="width: 100%; max-width: 100%;">
    <figcaption id="syns_connectors">Fig. 1. Sync connector pinouts on DAVIS 346</figcaption>
  </figure>
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/four_event_camera.jpg" alt="Image 2" style="width: 100%; max-width: 100%;">
    <figcaption id="four_event_camera">Fig. 2. Four event cameras are connect via external cables</figcaption>
  </figure>
</div> -->

<div class="row">
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <!-- Fallback to the original file -->
  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/syns_connectors.png" title="syns_connectors">
  <figcaption id="syns_connectors">Fig. 2. Sync connector pinouts on DAVIS 346</figcaption>
</picture>

</figure>

  </div>
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <!-- Fallback to the original file -->
  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/four_event_camera.jpg" title="four_event_camera">
  <figcaption id="four_event_camera">Fig. 3. Four event cameras are connect via external cables</figcaption>
</picture>

</figure>

  </div>
</div>

<p style="text-align: justify;">
  The synchronization connectors are HiRose HR10A-7R-4P (male, SYNC OUTPUT) and HR10A-7R-4S (female, SYNC INPUT) connectors. Cables should use the matching 
  connectors HR10A-7P-4S (female) and HR10A-7P-4P (male).
  Please note that to keep full electrical isolation between different cameras, the cable should not be shielded, or if it is, the shield should not connect one 
  end of the cable to the other.
  Input signals can be 3.3V or 5V, depending on the VDD_IN supplied externally, output signals are 5V, as is VDD_OUT.
  If you chain cameras together for synchronization, the clock and VDD will be 5V, for example.
</p>

<p style="text-align: justify;">
  Therefore, utilizing this sync connector, we connected four event cameras together (two DAVIS346 and two DVXplorer) as shown in the diagram below.
  Additionally, we replaced the event camera ROS driver <a href="https://gitlab.com/inivation/dv/dv-ros">Code</a> provided by Invitation Company with 
  our own driver <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM/tree/main/driver_code/dv-ros-master">Code</a>.
</p>

<p style="text-align: justify;">
  There are two key parameter in the driver code of event camera for synchronization, <mark>syncDevices</mark> and <mark> waitForSync </mark>
</p>

<div class="code-box">
  <code> &lt;rosparam param=&quot;syncDevices&quot;&gt;["series number of your event camera"]&lt;/rosparam&gt; </code>
</div>

<p style="text-align: justify;">
A list of other cameras connected with synchronization cable to this camera, If this list is empty, the camera node will not properly synchronize them.
</p>

<div class="code-box">
  <code>&lt;param name=&quot;waitForSync&quot; value=&quot;true&quot;/&gt;</code>
</div>

<p style="text-align: justify;">
  This means that it does not publish data until synchronization is complete.
  The launch file of our event camera synchronization can be seen in <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM/tree/main/driver_code/dv-ros-master/dv_ros_visualization/launch">Link</a>.
  We use an event camera as "master" while the other three event cameras is waiting on list.
  Through the series number of the event camera to avoid mis-match.
</p>


<p style="text-align: justify;">
  After synchronizing the clock cycles between two onboard computers, we set the image publishing frequency of DAVIS346 on onboard computer A to 20Hz, and the publishing frequency of the industrial camera on onboard computer B to 20Hz as well.
  Then, we placed a stopwatch in front of both cameras.
  We observed the stopwatch values for image topics with the same timestamps from both cameras.
  After multiple verifications, we concluded that the time difference between the DAVIS346 on onboard computer A and the industrial camera on onboard computer B, directly capturing images, was within 10ms, which aligns with our expectations.
</p>

<figure style="text-align: center;">
  <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_camera_synchronization.jpg" alt="Image description">
  <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/image_synchronization.jpg" alt="Image description">
  <figcaption>Fig. 4. Synchronization Testing between the Event Camera (left) and the Standard Camera (right) </figcaption>
</figure>

<p style="text-align: justify;">
  We further test the synchronization between the event and image data streams in DAVIS346 as following:
</p>

  <figure style="text-align: center;">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_vs_image_1.png" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_vs_image_2.png" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_vs_image_3.png" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_vs_image_4.png" alt="Image description">
    <!-- <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_camera_synchronization.jpg" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_camera_synchronization.jpg" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_camera_synchronization.jpg" alt="Image description">
    <img style="width: 48%;" src="https://arclab-hku.github.io/ecmd/assets/img/event_camera_synchronization.jpg" alt="Image description"> -->
    <figcaption>Fig. 5. Synchronization Testing between the Event and Image from DAVIS346 </figcaption>
  </figure>

<br>
<iframe src="//player.bilibili.com/player.html?aid=229390210&bvid=BV168411o7BJ&cid=1152522995&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="display: block; margin: 0 auto; width: 60%; height: 40vh;"></iframe>


<p><br></p>

<h3>2. Sensors Calibration</h3>
            
<p><br></p>
            
 <div class="row">
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <!-- Fallback to the original file -->
  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/sensors1.png" title="sensors1">

</picture>

</figure>

  </div>
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <!-- Fallback to the original file -->
  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/sensors2.png" title="sensors2">

</picture>

</figure>

  </div>
</div>

<!-- <p style="text-align: justify;">
For sensor calibration, we first define the coordinate of Xsens Mti-30 as the body frame. Then we meticulously calibrate the intrinsics of each sensor with the extrinsics between the external IMU and the rest sensors.  
More details of the calibration sequence, platform layout, and reports of calibration can be found on our website.
</p> -->

<p><br></p>

<h4>2.1. IMU Calibration</h4>

<p><br></p>

<p style="text-align: justify;">
  To calibrate the IMU, we position it on a level surface for a duration of three hours, recording the raw measurements. 
  Utilizing the Kalibr toolbox, we can accurately calibrate the random walk and Gaussian white noise of IMU.
</p>

<p><br></p>

<h4>2.2. Industrial Cameras Calibration</h4>

<p><br></p>

<p style="text-align: justify;">
  For industrial cameras, we move the sensor platform against the 9&times;7 checkerboard in the XYZ-axis and collect the sequence of RGB images and IMU.
  Then intrinsics calibration of industrial cameras is achieved by Kalibr toolbox, where the pinhole and radial-tangential camera models are adopted.
  The results of intrinsics calibration are shown in <a href="#Intrinsics calibration of industrial cameras">Fig. 6.</a>. 
</p>

<figure style="text-align: center;">
  <img style = "width: 70%" src="https://arclab-hku.github.io/ecmd/assets/img/calibration_results.png" alt="Image description">
  <figcaption id="Intrinsics calibration of industrial cameras">Fig. 6. Intrinsics calibration of industrial cameras</figcaption>
</figure>

<p><br></p>

<h4>2.3. Event Cameras Calibration</h4>

<p><br></p>

<p style="text-align: justify;">
  For event cameras, DAVIS346 can produce fixed-rated frames, enabling image-based calibration, while DVXplorer merely produces asynchronous event streams.
  Therefore, E2Calib is used to achieve image reconstruction from event streams(see <a href="#Event streams of checkerboard">Fig. 7.</a>).
  With the reconstructed checkerboard images in <a href="#Reconstructed image of checkerboard">Fig. 8.</a>, the intrinsics of event cameras could also be calibrated by Kalibr.
</p>

<div style="display: flex; justify-content: space-between;">
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/Event_streams_of_checkerboard.png" alt="Image 1" style="width: 100%; max-width: 100%;">
    <figcaption id="Event streams of checkerboard">Fig. 7. Event streams of checkerboard</figcaption>
  </figure>
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/Reconstructed_image_of_checkerboard.png" alt="Image 2" style="width: 100%; max-width: 100%;">
    <figcaption id="Reconstructed image of checkerboard">Fig. 8. Reconstructed image of checkerboard</figcaption>
  </figure>
</div>

<p><br></p>

<h4>2.4. Calibration of Infrared Cameras</h4>

<p><br></p>

<p style="text-align: justify;">
  Due to infrared cameras solely capturing the temperature rather than the intensity difference, we design a distinct 9&times;7 checkerboard to 
  make the pattern detectable for infrared cameras. 
  As shown in <a href="#PCB checkerboard">Fig. 9.</a>, the checkerboard intervals are affixed with aluminum materials, and then using a heating plate 
  to raise the temperature of the checkerboard.
  Since the superior thermal dissipation of aluminum compared to plastic, a temperature contrast emerges between the two materials, enabling infrared 
  cameras to distinctly capture the lattice shape of the checkerboard, as in <a href="#Infrared image of heated checkerboard">Fig. 10.</a>.
  With the special infrared image of the checkerboard, intrinsic can be calibrated by Kalibr.
</p>

<!-- <div style="display: flex; justify-content: space-between;">
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/infrared_calibration.JPG" alt="Image 1" style="width: 100%; max-width: 100%;">
    <figcaption id="PCB checkerboard">Fig. 4. PCB checkerboard</figcaption>
  </figure>
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/infrared_image.png" alt="Image 2" style="width: 100%; max-width: 100%;">
    <figcaption id="Infrared image of heated checkerboard">Fig. 5. Infrared image of heated checkerboard</figcaption>
  </figure>
</div> -->

<div class="row">
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/infrared_calibration.JPG" title="sensors1">
  <figcaption id="PCB checkerboard">Fig. 9. PCB checkerboard</figcaption>
</picture>

</figure>

  </div>
  <div class="col-sm mt-3 mt-md-0">
      <figure>

<picture>

  <img class="img-fluid rounded z-depth-1" src="https://arclab-hku.github.io/ecmd/assets/img/infrared_image.png" title="sensors2">
  <figcaption id="Infrared image of heated checkerboard">Fig. 10. Infrared image of heated checkerboard</figcaption>
</picture>

</figure>

  </div>
</div>

<p><br></p>

<h4>2.5. Calibration between Camera and IMU</h4>

<p><br></p>

<p style="text-align: justify;">
  After completing intrinsic calibration, we move the sensor suite in front of checkerboards along the XYZ-RPY-axis and collect data simultaneously.
  Subsequently, the extrinsic and the temporal offset between all cameras and IMU could be estimated using Kalibr. 
</p>

<div style="display: flex; justify-content: space-between;text-align: center;">
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/extrinsics.png" alt="Image 1" style="width: 90%; max-width: 90%;">
    <figcaption id="extrinsics">Fig. 11. The extrinsics between left industrial camera and IMU</figcaption>
  </figure>
</div>

<p><br></p>

<h4>2.6. Calibration between LiDAR and IMU</h4>

<p><br></p>

<p style="text-align: justify;">
  For the calibration of mechanical LiDAR, LI-Init is capable of achieving temporal and spatial calibration for LiDAR and IMU without checkerboards 
  or extra devices in <a href="#lidar_calibration">Fig. 12.</a>. 
  We rotate and move the device around the XYZ-axis to ensure sufficient excitation until the data accumulation is completed, thus we acquire the extrinsic 
  transformation between LiDAR and IMU.
</p>

<div style="display: flex; justify-content: space-between;text-align: center;">
  <figure>
    <img src="https://arclab-hku.github.io/ecmd/assets/img/lidar_calibration.png" alt="Image 1" style="width: 70%; max-width: 70%;">
    <figcaption id="lidar_calibration">Fig. 12. Calibration between LiDAR and IMU</figcaption>
  </figure>
</div>

<p><br></p>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="nofixed-bottom">
      <div class="container mt-0" style="width:100%;text-align:center;">
        © 2023 Adaptive Robotics Controls Lab (Arclab), The University of HongKong. All rights reserved.
      </div>
    </footer> 

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/vector/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/vector/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/vector/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

